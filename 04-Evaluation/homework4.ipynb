{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-10-20 15:11:15--  https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 80876 (79K) [text/plain]\n",
      "Saving to: ‘course_lead_scoring.csv’\n",
      "\n",
      "course_lead_scoring 100%[===================>]  78.98K  --.-KB/s    in 0.08s   \n",
      "\n",
      "2025-10-20 15:11:15 (1018 KB/s) - ‘course_lead_scoring.csv’ saved [80876/80876]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = 'https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv'\n",
    "!wget $data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the missing values are presented in the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source                 128\n",
       "industry                    134\n",
       "number_of_courses_viewed      0\n",
       "annual_income               181\n",
       "employment_status           100\n",
       "location                     63\n",
       "interaction_count             0\n",
       "lead_score                    0\n",
       "converted                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('course_lead_scoring.csv')\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source                  object\n",
       "industry                     object\n",
       "number_of_courses_viewed      int64\n",
       "annual_income               float64\n",
       "employment_status            object\n",
       "location                     object\n",
       "interaction_count             int64\n",
       "lead_score                  float64\n",
       "converted                     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For caterogiral features, replace them with 'NA'.\n",
    "\n",
    "For numerical features, replace with with 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = df.select_dtypes(include=['object']).columns\n",
    "df[categorical_features]= df[categorical_features].fillna('NA')\n",
    "\n",
    "numerical_features = df.select_dtypes(include=['number']).columns\n",
    "df[numerical_features]= df[numerical_features].fillna(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into 3 parts: train/validation/test with 60%/20%/20% distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=1)\n",
    "df_train,df_val = train_test_split(df_full_train, test_size=0.25, random_state=1)\n",
    "\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "# Ectract the desired target for classification\n",
    "\n",
    "y_train = df_train.converted.values\n",
    "y_val = df_val.converted.values\n",
    "y_test = df_test.converted.values\n",
    "\n",
    "del df_train['converted']\n",
    "del df_val['converted']\n",
    "del df_test['converted']\n",
    "\n",
    "numerical_features= numerical_features.drop(['converted'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1. ROC AUC feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the AUC score for the  number_of_courses_viewed is:  0.7635680590007088\n",
      "the AUC score for the  annual_income is:  0.5519578313253012\n",
      "the AUC score for the  interaction_count is:  0.738270176293409\n",
      "the AUC score for the  lead_score is:  0.6144993577250176\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "for numerical in numerical_features:\n",
    "    score = roc_auc_score(y_train,df_train[numerical])\n",
    "    if score<0.5:\n",
    "        df_train[numerical]=-df_train[numerical]\n",
    "        score = roc_auc_score(y_train,df_train[numerical])\n",
    "    print(\"the AUC score for the \",numerical,\"is: \",score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "number_of_courses_viewed has the highest AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features= numerical_features.tolist()\n",
    "categorical_features = categorical_features.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2. Model AUC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the AUC score on the validation dataset is:  0.817\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "train_dicts = df_train[categorical_features+ numerical_features].to_dict(orient='records')\n",
    "\n",
    "dv = DictVectorizer(sparse=False)\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "val_dicts = df_val[categorical_features + numerical_features].to_dict(orient='records')\n",
    "X_val = dv.transform(val_dicts)\n",
    "\n",
    "y_pred = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "#the AUC of this model on the validation dataset\n",
    "\n",
    "roc_auc = roc_auc_score(y_val, y_pred)\n",
    "print(\"the AUC score on the validation dataset is: \", round(roc_auc,3))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
