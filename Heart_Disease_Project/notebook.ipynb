{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f76fe73",
   "metadata": {},
   "source": [
    "1- Importing librarie for data manipulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c66f9d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca3eec4",
   "metadata": {},
   "source": [
    "2- Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb3c4109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>294</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   52    1   0       125   212    0        1      168      0      1.0      2   \n",
       "1   53    1   0       140   203    1        0      155      1      3.1      0   \n",
       "2   70    1   0       145   174    0        1      125      1      2.6      0   \n",
       "3   61    1   0       148   203    0        1      161      0      0.0      2   \n",
       "4   62    0   0       138   294    1        1      106      0      1.9      1   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   2     3       0  \n",
       "1   0     3       0  \n",
       "2   0     3       0  \n",
       "3   1     3       0  \n",
       "4   3     2       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/heart.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "63423826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1025 entries, 0 to 1024\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       1025 non-null   int64  \n",
      " 1   sex       1025 non-null   int64  \n",
      " 2   cp        1025 non-null   int64  \n",
      " 3   trestbps  1025 non-null   int64  \n",
      " 4   chol      1025 non-null   int64  \n",
      " 5   fbs       1025 non-null   int64  \n",
      " 6   restecg   1025 non-null   int64  \n",
      " 7   thalach   1025 non-null   int64  \n",
      " 8   exang     1025 non-null   int64  \n",
      " 9   oldpeak   1025 non-null   float64\n",
      " 10  slope     1025 non-null   int64  \n",
      " 11  ca        1025 non-null   int64  \n",
      " 12  thal      1025 non-null   int64  \n",
      " 13  target    1025 non-null   int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 112.2 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "feaa7fb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age         0\n",
       "sex         0\n",
       "cp          0\n",
       "trestbps    0\n",
       "chol        0\n",
       "fbs         0\n",
       "restecg     0\n",
       "thalach     0\n",
       "exang       0\n",
       "oldpeak     0\n",
       "slope       0\n",
       "ca          0\n",
       "thal        0\n",
       "target      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for missing values\n",
    "df.isnull().sum()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3c4e2e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.00000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.434146</td>\n",
       "      <td>0.695610</td>\n",
       "      <td>0.942439</td>\n",
       "      <td>131.611707</td>\n",
       "      <td>246.00000</td>\n",
       "      <td>0.149268</td>\n",
       "      <td>0.529756</td>\n",
       "      <td>149.114146</td>\n",
       "      <td>0.336585</td>\n",
       "      <td>1.071512</td>\n",
       "      <td>1.385366</td>\n",
       "      <td>0.754146</td>\n",
       "      <td>2.323902</td>\n",
       "      <td>0.513171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.072290</td>\n",
       "      <td>0.460373</td>\n",
       "      <td>1.029641</td>\n",
       "      <td>17.516718</td>\n",
       "      <td>51.59251</td>\n",
       "      <td>0.356527</td>\n",
       "      <td>0.527878</td>\n",
       "      <td>23.005724</td>\n",
       "      <td>0.472772</td>\n",
       "      <td>1.175053</td>\n",
       "      <td>0.617755</td>\n",
       "      <td>1.030798</td>\n",
       "      <td>0.620660</td>\n",
       "      <td>0.500070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>211.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>240.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>275.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age          sex           cp     trestbps        chol  \\\n",
       "count  1025.000000  1025.000000  1025.000000  1025.000000  1025.00000   \n",
       "mean     54.434146     0.695610     0.942439   131.611707   246.00000   \n",
       "std       9.072290     0.460373     1.029641    17.516718    51.59251   \n",
       "min      29.000000     0.000000     0.000000    94.000000   126.00000   \n",
       "25%      48.000000     0.000000     0.000000   120.000000   211.00000   \n",
       "50%      56.000000     1.000000     1.000000   130.000000   240.00000   \n",
       "75%      61.000000     1.000000     2.000000   140.000000   275.00000   \n",
       "max      77.000000     1.000000     3.000000   200.000000   564.00000   \n",
       "\n",
       "               fbs      restecg      thalach        exang      oldpeak  \\\n",
       "count  1025.000000  1025.000000  1025.000000  1025.000000  1025.000000   \n",
       "mean      0.149268     0.529756   149.114146     0.336585     1.071512   \n",
       "std       0.356527     0.527878    23.005724     0.472772     1.175053   \n",
       "min       0.000000     0.000000    71.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000   132.000000     0.000000     0.000000   \n",
       "50%       0.000000     1.000000   152.000000     0.000000     0.800000   \n",
       "75%       0.000000     1.000000   166.000000     1.000000     1.800000   \n",
       "max       1.000000     2.000000   202.000000     1.000000     6.200000   \n",
       "\n",
       "             slope           ca         thal       target  \n",
       "count  1025.000000  1025.000000  1025.000000  1025.000000  \n",
       "mean      1.385366     0.754146     2.323902     0.513171  \n",
       "std       0.617755     1.030798     0.620660     0.500070  \n",
       "min       0.000000     0.000000     0.000000     0.000000  \n",
       "25%       1.000000     0.000000     2.000000     0.000000  \n",
       "50%       1.000000     0.000000     2.000000     1.000000  \n",
       "75%       2.000000     1.000000     3.000000     1.000000  \n",
       "max       2.000000     4.000000     3.000000     1.000000  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500d2cc6",
   "metadata": {},
   "source": [
    "Attribute Information from https://www.kaggle.com/datasets/johnsmith88/heart-disease-dataset/data:\n",
    "    \n",
    "    - age\n",
    "\n",
    "    - sex (0 for female and 1 for Male)\n",
    "\n",
    "    - chest pain type (4 values)                          --->CATEGORICAL FEATURE\n",
    "\n",
    "    - resting blood pressure\n",
    "\n",
    "    - serum cholestoral in mg/dl\n",
    "\n",
    "    - fasting blood sugar > 120 mg/dl IT TAKES TWO VALUES --->CATEGORICAL FEATURE\n",
    "\n",
    "    - resting electrocardiographic results (values 0,1,2) --->CATEGORICAL FEATURE\n",
    "\n",
    "    - maximum heart rate achieved\n",
    "\n",
    "    - exercise induced angina                             --->CATEGORICAL FEATURE\n",
    "\n",
    "    - oldpeak = ST depression induced by exercise relative to rest\n",
    "\n",
    "    - the slope of the peak exercise ST segment           --->CATEGORICAL FEATURE\n",
    "\n",
    "    - number of major vessels (0-3) colored by flourosopy --->CATEGORICAL FEATURE\n",
    "    \n",
    "    - thal: 0 = normal; 1 = fixed defect; 2 = reversable defect --->CATEGORICAL FEATURE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4912c81f",
   "metadata": {},
   "source": [
    "3- Importing scikit learn for the features extraction and model training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "60b342a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2b97a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /usr/local/python/3.12.1/lib/python3.12/site-packages (4.67.1)\n"
     ]
    }
   ],
   "source": [
    "%pip install tqdm\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2eee4d",
   "metadata": {},
   "source": [
    "Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "90757d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=1)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=1)\n",
    "\n",
    "# Reset indexes\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "# Separate target variable\n",
    "y_train = df_train.target.values\n",
    "y_val = df_val.target.values\n",
    "y_test = df_test.target.values\n",
    "\n",
    "# Remove target from dataframes\n",
    "del df_train['target']\n",
    "del df_val['target']\n",
    "del df_test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "761569de",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = ['age', 'sex', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "categorical = ['cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52a9e76",
   "metadata": {},
   "source": [
    "4- Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f65d276e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train (df_train, y_train, C=1.0):\n",
    "    train_dicts = df_train[categorical + numerical].to_dict(orient='records')\n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    X_train = dv.fit_transform(train_dicts)\n",
    "    \n",
    "    model = LogisticRegression(C=C, max_iter=len(X_train)*10)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    return dv, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7955d32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dv, model = train(df_train, y_train, C=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f3227f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(df, dv, model):\n",
    "    dicts = df[categorical + numerical].to_dict(orient='records')\n",
    "    X = dv.transform(dicts)\n",
    "    y_pred = model.predict_proba(X)[:, 1]\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "69f40b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC on validation set: 0.914\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict(df_val, dv, model)\n",
    "\n",
    "auc = roc_auc_score(y_val, y_pred)\n",
    "print(f\"AUC on validation set: {auc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430d9f55",
   "metadata": {},
   "source": [
    "5- Tuning differente parameters for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84238f2",
   "metadata": {},
   "source": [
    "Manual tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b5e25060",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:00<00:01,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=0.001: AUC=0.799 +/- 0.023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:00<00:01,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=0.01: AUC=0.888 +/- 0.024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:01<00:01,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=0.1: AUC=0.915 +/- 0.028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:02<00:01,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=1: AUC=0.917 +/- 0.027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [00:03<00:00,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=10: AUC=0.917 +/- 0.026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:04<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=100: AUC=0.917 +/- 0.026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_splits = 5\n",
    "\n",
    "for C in tqdm([0.001, 0.01, 0.1, 1, 10, 100]):\n",
    "    aucs = []\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=1)\n",
    "    for train_index, val_index in kf.split(df_full_train):\n",
    "        df_train = df_full_train.iloc[train_index].copy()\n",
    "        df_val = df_full_train.iloc[val_index].copy()\n",
    "        \n",
    "        y_train = df_train.target.values\n",
    "        y_val = df_val.target.values\n",
    "        \n",
    "        df_train = df_train.drop('target', axis=1)\n",
    "        df_val = df_val.drop('target', axis=1)\n",
    "        \n",
    "        dv, model = train(df_train, y_train, C=C)\n",
    "        y_pred = predict(df_val, dv, model)\n",
    "        auc = roc_auc_score(y_val, y_pred)\n",
    "        aucs.append(auc)\n",
    "    print(f\"C={C}: AUC={np.mean(aucs):.3f} +/- {np.std(aucs):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512090f0",
   "metadata": {},
   "source": [
    "Using GridSearchCV, a scikit-learn function that performs hyperparameter tuning automaticaly by training and evaluating the ML model using different combinations of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2eb7e82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best AUC: 0.915\n",
      "Best C: 1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "grid_search = GridSearchCV(\n",
    "    LogisticRegression(max_iter=len(df_full_train)*10),\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='roc_auc',  # or 'accuracy', 'f1', 'roc_auc' etc.\n",
    "    verbose=1  #show process\n",
    "    #return_train_score=True #detect overfitting but optional\n",
    ")\n",
    "dicts = df_full_train[categorical+numerical].to_dict(orient='records')\n",
    "dv2 = DictVectorizer(sparse=False)\n",
    "X_train = dv2.fit_transform(dicts)\n",
    "\n",
    "y_train = df_full_train.target.values\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_C = grid_search.best_params_['C']\n",
    "best_auc = grid_search.best_score_\n",
    "print(f\"Best AUC: {best_auc:.3f}\")\n",
    "print(f\"Best C: {best_C}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c3b107",
   "metadata": {},
   "source": [
    "Choosing the best C: 1 and examine the Evaluation Metrics on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7b8d6fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC on test set: 0.921\n",
      "\n",
      "\n",
      "Confusion Matrix on the test dataset c(threshold=0.5):\n",
      "                Predicted Pos  Predicted Neg\n",
      "Actual Pos      86 (89.58%)    10 (10.42%)\n",
      "Actual Neg      29 (26.61%)    80 (73.39%)\n",
      "\n",
      "Metrics:\n",
      "  Sensitivity/Recall: 0.896\n",
      "  Specificity:        0.734\n",
      "  Precision:          0.748\n",
      "  Accuracy:           0.810\n"
     ]
    }
   ],
   "source": [
    "dv, model = train(df_full_train, df_full_train.target.values, C=1)\n",
    "y_pred = predict(df_test, dv, model)\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "print(f\"AUC on test set: {auc:.3f}\\n\")\n",
    "\n",
    "actual_positive = (y_test == 1)\n",
    "actual_negative = (y_test == 0)\n",
    "\n",
    "t=0.5\n",
    "predicted_positive = (y_pred >= t)\n",
    "predicted_negative = (y_pred < t)\n",
    "\n",
    "tp = (predicted_positive & actual_positive).sum()\n",
    "tn = (predicted_negative & actual_negative).sum()\n",
    "fp = (predicted_positive & actual_negative).sum()\n",
    "fn = (predicted_negative & actual_positive).sum()\n",
    "\n",
    "#print(tp)\n",
    "\n",
    "total_pos = actual_positive.sum()\n",
    "total_neg = (~actual_positive).sum()\n",
    "\n",
    "print(f\"\\nConfusion Matrix on the test dataset c(threshold={t}):\")\n",
    "print(f\"{'':>15} Predicted Pos  Predicted Neg\")\n",
    "print(f\"Actual Pos      {tp} ({tp/total_pos:.2%})    {fn} ({fn/total_pos:.2%})\")\n",
    "print(f\"Actual Neg      {fp} ({fp/total_neg:.2%})    {tn} ({tn/total_neg:.2%})\")\n",
    "print(f\"\\nMetrics:\")\n",
    "print(f\"  Sensitivity/Recall: {tp/total_pos:.3f}\")\n",
    "print(f\"  Specificity:        {tn/total_neg:.3f}\")\n",
    "print(f\"  Precision:          {tp/(tp+fp):.3f}\")\n",
    "print(f\"  Accuracy:           {(tp+tn)/(tp+tn+fp+fn):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b334b0d8",
   "metadata": {},
   "source": [
    "6- Try to train the model in another ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3aeb1dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicated rows: 723\n"
     ]
    }
   ],
   "source": [
    "# Display duplicated rows\n",
    "duplicated_rows = df[df.duplicated()].sort_values(by=list(df.columns))\n",
    "print(f\"Number of duplicated rows: {len(duplicated_rows)}\")\n",
    "#print(\"\\nThe duplicated rows:\")\n",
    "#duplicated_rows                                                                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c07495e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 302 entries, 0 to 301\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       302 non-null    int64  \n",
      " 1   sex       302 non-null    int64  \n",
      " 2   cp        302 non-null    int64  \n",
      " 3   trestbps  302 non-null    int64  \n",
      " 4   chol      302 non-null    int64  \n",
      " 5   fbs       302 non-null    int64  \n",
      " 6   restecg   302 non-null    int64  \n",
      " 7   thalach   302 non-null    int64  \n",
      " 8   exang     302 non-null    int64  \n",
      " 9   oldpeak   302 non-null    float64\n",
      " 10  slope     302 non-null    int64  \n",
      " 11  ca        302 non-null    int64  \n",
      " 12  thal      302 non-null    int64  \n",
      " 13  target    302 non-null    int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 33.2 KB\n"
     ]
    }
   ],
   "source": [
    "df = df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ddbb95e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=1)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=1)\n",
    "\n",
    "# Reset indexes\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "# Separate target variable\n",
    "y_train = df_train.target.values\n",
    "y_val = df_val.target.values\n",
    "y_test = df_test.target.values\n",
    "\n",
    "# Remove target from dataframes\n",
    "del df_train['target']\n",
    "del df_val['target']\n",
    "del df_test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ef29ad81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best AUC: 0.904\n",
      "Best C: 1\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "grid_search = GridSearchCV(\n",
    "    LogisticRegression(max_iter=len(df_full_train)*10),\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='roc_auc',  # or 'accuracy', 'f1', 'roc_auc' etc.\n",
    "    verbose=1  #show process\n",
    "    #return_train_score=True #detect overfitting but optional\n",
    ")\n",
    "dicts = df_full_train[categorical+numerical].to_dict(orient='records')\n",
    "dv3 = DictVectorizer(sparse=False)\n",
    "X_train = dv3.fit_transform(dicts)\n",
    "\n",
    "y_train = df_full_train.target.values\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_C = grid_search.best_params_['C']\n",
    "best_auc = grid_search.best_score_\n",
    "print(f\"Best AUC: {best_auc:.3f}\")\n",
    "print(f\"Best C: {best_C}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "880badec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC on test set: 0.864\n",
      "\n",
      "\n",
      "Confusion Matrix (threshold=0.5):\n",
      "                Predicted Pos  Predicted Neg\n",
      "Actual Pos      29 (82.86%)    6 (17.14%)\n",
      "Actual Neg      6 (23.08%)    20 (76.92%)\n",
      "\n",
      "Metrics:\n",
      "  Sensitivity/Recall: 0.829\n",
      "  Specificity:        0.769\n",
      "  Precision:          0.829\n",
      "  Accuracy:           0.803\n"
     ]
    }
   ],
   "source": [
    "dv, model = train(df_full_train, df_full_train.target.values, C=1)\n",
    "y_pred = predict(df_test, dv, model)\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "print(f\"AUC on test set: {auc:.3f}\\n\")\n",
    "\n",
    "actual_positive = (y_test == 1)\n",
    "actual_negative = (y_test == 0)\n",
    "\n",
    "t=0.5\n",
    "predicted_positive = (y_pred >= t)\n",
    "predicted_negative = (y_pred < t)\n",
    "\n",
    "tp = (predicted_positive & actual_positive).sum()\n",
    "tn = (predicted_negative & actual_negative).sum()\n",
    "fp = (predicted_positive & actual_negative).sum()\n",
    "fn = (predicted_negative & actual_positive).sum()\n",
    "\n",
    "#print(tp)\n",
    "\n",
    "total_pos = actual_positive.sum()\n",
    "total_neg = (~actual_positive).sum()\n",
    "\n",
    "print(f\"\\nConfusion Matrix (threshold={t}):\")\n",
    "print(f\"{'':>15} Predicted Pos  Predicted Neg\")\n",
    "print(f\"Actual Pos      {tp} ({tp/total_pos:.2%})    {fn} ({fn/total_pos:.2%})\")\n",
    "print(f\"Actual Neg      {fp} ({fp/total_neg:.2%})    {tn} ({tn/total_neg:.2%})\")\n",
    "print(f\"\\nMetrics:\")\n",
    "print(f\"  Sensitivity/Recall: {tp/total_pos:.3f}\")\n",
    "print(f\"  Specificity:        {tn/total_neg:.3f}\")\n",
    "print(f\"  Precision:          {tp/(tp+fp):.3f}\")\n",
    "print(f\"  Accuracy:           {(tp+tn)/(tp+tn+fp+fn):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70a1961",
   "metadata": {},
   "source": [
    "After analyzing the model's performance, we found that the model trained with the original dataset and inverted regularization strength (c=1) showed good performance.\n",
    "\n",
    "However, when we dropped the duplicated dataset, the model lost some comprehension of the feature dataset. However, this process may be beneficial in other situations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
